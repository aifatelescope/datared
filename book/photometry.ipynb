{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometry\n",
    "\n",
    "On this page we'll detect sources and perform simple aperture photometry (along other measurements) for each pre-reduced image.\n",
    "The same procedure could of course also be applied to coadded images.\n",
    "\n",
    "As before, you could copy or write the code shown below in a script, or alternatively directly download this page as a {download}`jupyter notebook <./photometry.ipynb>` file.\n",
    "\n",
    "To run the code, you'll need the module `dataredconfig.py`, as explained [here](./data.md).\n",
    "\n",
    "```{note}\n",
    "The photometry presented here is sufficient for our purposes, but remains extremely simple. Notably, it ignores the effect of variable seeing (in time and/or accross filters). The next steps to improve upon the minimal approach shown here would be to perform a PSF homogeneization or to use PSF-fitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataredconfig\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import astropy\n",
    "import astropy.visualization\n",
    "from astropy import units as u\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ccdproc\n",
    "import photutils\n",
    "\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll ignore some astropy warnings that get raised as our FITS headers (from NINA) are not 100% standards compliant.\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=astropy.wcs.FITSFixedWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting the correct path to the pre-reduced science frames to work on:\n",
    "#science_files_dir = dataredconfig.work_dir / \"LIGHT_PRERED\" # In case astrometric calibration was already performed before the pre-reduction\n",
    "science_files_dir = dataredconfig.work_dir / \"ASTROMETRY\"\n",
    "science_files = ccdproc.ImageFileCollection(science_files_dir, keywords=dataredconfig.ifc_header_keywords)\n",
    "\n",
    "# Where to write the catalogs:\n",
    "photometry_dir = dataredconfig.work_dir / \"PHOTOMETRY\"\n",
    "photometry_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Overview of all available files:\n",
    "science_files.summary\n",
    "# You may want to try this instead, for a better display:\n",
    "#science_files.summary.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: selecting the science frames to run on : \n",
    "object_to_process = \"HD92670\"\n",
    "\n",
    "science_files = science_files.filter(object=object_to_process)\n",
    "\n",
    "#science_files.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will measure photometry on all these files.\n",
    "But we start by picking one reference image, used to detect sources and to check the overall procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image_filepath = science_files.files[0]\n",
    "ref_image = ccdproc.CCDData.read(ref_image_filepath)\n",
    "\n",
    "if(ref_image.wcs is None): # Performing forced photometry requires each frame to have a good WCS. This test is just to avoid obvious mistakes.\n",
    "    raise RuntimeError(\"The image has no WCS, make sure you specify the correct directory (i.e., with WCS) above!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating and subtracting the background\n",
    "\n",
    "Some of the following tasks will be run on several images, and we therefore define them as very simple functions.\n",
    "Of course, depending on the data to be processed, you might want to adjust (hard-coded) parameters in these functions. They are only provided as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_background(image):\n",
    "    \"\"\"Function to estimate the background (in form of an image),\n",
    "    and the root-mean-square deviation (RMS) of the background.\n",
    "    \n",
    "    Parameters:\n",
    "    image: a CCDData object\n",
    "\n",
    "    Returns:\n",
    "    background, background_rms: two numpy arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    bkg = photutils.background.Background2D(\n",
    "        image.data,\n",
    "        box_size=(500, 500),\n",
    "        filter_size=(3, 3),\n",
    "        bkg_estimator=photutils.background.MedianBackground())\n",
    "    \n",
    "    return bkg.background, bkg.background_rms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run this on the reference image\n",
    "background, background_rms = estimate_background(ref_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the background image\n",
    "plt.figure()\n",
    "plt.imshow(background, origin='lower', cmap='Greys_r', interpolation='nearest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We subtract the background from the reference image\n",
    "ref_image_noback = ref_image.subtract(ccdproc.CCDData(background, unit=\"adu\"))\n",
    "\n",
    "# And we define a \"threshold\" image for this reference frame,\n",
    "# whose values are multiples of the estimated RMS of the background in each pixel.\n",
    "# (RMS is an estimate of the standard deviation, so 3*RMS is \"3 sigma\" above the background)\n",
    "threshold = 3.0 * background_rms # this is an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source detection and measurement\n",
    "\n",
    "We now detect sources (as groups of connected pixels above the threshold) and measure their exact positions (among other parameters), on the selected reference image. Let's nevertheless group all this in a function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_measure(image, threshold):\n",
    "    \"\"\"Function to detect and measure sources.\n",
    "    This is close to what Source Extractor typically does.\n",
    "    \n",
    "    Parameters:\n",
    "    image: a CCDData object\n",
    "    threshold: a 2D-array with threshold values\n",
    "\n",
    "    Returns:\n",
    "    An Astropy Table with source positions (from  windowed centroids, \n",
    "    both in pixel and sky coordinates) and other measurements.\n",
    "    \"\"\"\n",
    "    data = image.data \n",
    "\n",
    "    # Filtering (convolving with a 2D Gaussian) for better source detection\n",
    "    kernel = photutils.segmentation.make_2dgaussian_kernel(fwhm=4.0, size=21)  # FWHM in pixels\n",
    "    convolved_data = astropy.convolution.convolve(data, kernel)\n",
    "\n",
    "    # Segmenting the image\n",
    "    finder = photutils.segmentation.SourceFinder(npixels=4, connectivity=4, progress_bar=False)\n",
    "    segment_map = finder(convolved_data, threshold)\n",
    "    #segment_map = finder(data, threshold) # One could also run this on the unfiltered image\n",
    "\n",
    "    # And measuring sources\n",
    "    source_catalog = photutils.segmentation.SourceCatalog(data, segment_map, convolved_data=convolved_data, wcs=image.wcs)\n",
    "    source_table = source_catalog.to_table(\n",
    "        columns=[\"xcentroid_win\", \"ycentroid_win\", \"sky_centroid_win\",\n",
    "                 \"fwhm\", \"max_value\", \"kron_flux\", \"segment_flux\", \"segment_area\"]\n",
    "        )\n",
    "\n",
    "    return astropy.table.Table(source_table) # We convert the QTable to a Table, better for later FITS writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this on the reference image\n",
    "ref_catalog = detect_and_measure(ref_image_noback, threshold)\n",
    "\n",
    "print(f\"Reference catalog: {len(ref_catalog)} sources detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running a detection, it's almost mandatory to check the result with a visualization! We do this with the following interactive Figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure that overplots the image and the positions of the detected sources\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(projection=ref_image_noback.wcs)\n",
    "ax.imshow(ref_image_noback.data, origin='lower', cmap='Greys_r', interpolation='nearest',\n",
    "    norm=astropy.visualization.simple_norm(ref_image_noback.data, stretch=\"log\", min_cut=-20, max_cut=2000))\n",
    "ax.scatter(\n",
    "    ref_catalog[\"xcentroid_win\"],\n",
    "    ref_catalog[\"ycentroid_win\"],\n",
    "    transform=ax.get_transform('pixel'),\n",
    "    s=50, # The size of these markers is not related to any measurement apertures!\n",
    "    edgecolor='red', facecolor='none'\n",
    "    )\n",
    "ax.grid(color='white', ls='solid')\n",
    "ax.set_xlabel('RA')\n",
    "ax.set_ylabel('Dec')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in and check if all relevant sources are detected. If there are issues, one might have to adjust the sensitivity of the detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this catalog smaller, for testing:\n",
    "ref_catalog = ref_catalog[ref_catalog[\"kron_flux\"] > 10000] # pick the brightest sources\n",
    "len(ref_catalog)\n",
    "\n",
    "# Rerun the vizualisation above to see the effect..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note} \n",
    "A large reference catalog will slow down the photometry. It's helpful to adapt the flux threshold above to keep mainly those stars you actually care about, and not every tiny detection.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, we write the reference catalog in this directory.\n",
    "# It contains the aperture positions.\n",
    "ref_catalog.write(photometry_dir / f\"ref_catalog_{object_to_process}.fits\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forced aperture photometry\n",
    "\n",
    "We'll now perform forced aperture photometry on all science images of our target, with a series of aperture sizes (radii given in arcseconds in the code below).\n",
    "This means that we use the sky coordinates of the sources detected in the reference frame to place the same apertures on all dithered exposures of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group all steps of the photometric measurement into one function:\n",
    "\n",
    "def measure_photometry(image, sky_positions):\n",
    "    \"\"\"Function for forced aperture photometry given the provided sky_positions.\n",
    "    This is somehow similar to running Source Extractor in \"dual image mode\".\n",
    "\n",
    "    Parameters:\n",
    "    image: a CCDData object\n",
    "    sky_positions: a list or column of aperture positions, in sky coordinates (i.e. as SkyCoord objects)\n",
    "\n",
    "    Returns:\n",
    "    An Astropy Table with measurements for several aperture radii at the given positions.\n",
    "    \"\"\"\n",
    "\n",
    "    tstart = time()\n",
    "        \n",
    "    # Estimate and subtract the background:\n",
    "    background, _ = estimate_background(image)\n",
    "    image_noback = image.subtract(ccdproc.CCDData(background, unit=\"adu\"))\n",
    "\n",
    "    tend = time()\n",
    "    print(f\"Background subtraction took {tend-tstart:.2f} sec\")\n",
    "    \n",
    "    aperture_radii = [4, 6, 8, 10] # In arcsec\n",
    "\n",
    "    tstart = time()\n",
    "    # We first generate a separate catalog for each aperture radius, and combine these afterwards\n",
    "    aperture_catalogs = []\n",
    "    for r in aperture_radii:\n",
    "\n",
    "        apertures = photutils.aperture.SkyCircularAperture(sky_positions, r=r*u.arcsec)\n",
    "        aperture_measurements = photutils.aperture.ApertureStats(image_noback.data, aperture=apertures, wcs=image_noback.wcs)\n",
    "        \n",
    "        if r <= 5:\n",
    "            aperture_catalog = aperture_measurements.to_table(columns=[\"fwhm\", \"elongation\", \"sum\"])\n",
    "            # For some reason these fwhm and elongation sometimes lead to excessive runtime for large apertures (getting stuck...), to be investigated\n",
    "            # In case of trouble, replace the line above by the following, to measure only the flux:\n",
    "            #aperture_catalog = aperture_measurements.to_table(columns=[\"sum\"])\n",
    "        else:\n",
    "            aperture_catalog = aperture_measurements.to_table(columns=[\"sum\"])\n",
    "\n",
    "        # Rename columns by adding the aperture radius, to get for example \"sum_4\" instead of sum\n",
    "        for name in aperture_catalog.colnames:\n",
    "            aperture_catalog.rename_column(name, new_name=f\"{name}_{str(r)}\")\n",
    "        \n",
    "        aperture_catalogs.append(aperture_catalog)\n",
    "    \n",
    "    # And now merge these catalogs into a single one:\n",
    "    merged_catalog = astropy.table.hstack(aperture_catalogs,\n",
    "        join_type=\"exact\", metadata_conflicts=\"silent\"\n",
    "        )\n",
    "    \n",
    "    tend = time()\n",
    "    print(f\"Photometry took {tend-tstart:.2f} sec\")\n",
    "    return merged_catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# As a test, we run this on the ref_image.\n",
    "# For this we read the ref image again, as the one in memory already has the background subtracted.\n",
    "ref_image = ccdproc.CCDData.read(ref_image_filepath)\n",
    "ref_photo_cat = measure_photometry(ref_image, ref_catalog[\"sky_centroid_win\"])\n",
    "print(ref_photo_cat.colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this stage one could inspect the aperture photometry catalog, and make for instance a magnitude versus size plot to see the stellar locus.\n",
    "# We'll skip this here, as our current size measurements (if done at all) are not that great -- to be improved.\n",
    "\n",
    "#ref_photo_cat[\"mag_8\"] = -2.5 * np.log10(ref_photo_cat[\"sum_8\"].value)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.scatter(\n",
    "#    ref_photo_cat[\"fwhm_8\"].value, \n",
    "#    ref_photo_cat[\"mag_8\"], \n",
    "#    c=ref_photo_cat[\"elongation_8\"].value,\n",
    "#    vmin=1.0, vmax=1.5,\n",
    "#    cmap=\"jet\",\n",
    "#    s=15\n",
    "#)\n",
    "#plt.gca().invert_yaxis()\n",
    "#plt.colorbar(label=\"Elongation\")\n",
    "#plt.xlabel(\"FWHM [pix]\")\n",
    "#plt.ylabel(\"Instrumental magnitude\")\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply this measurement function to all images of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read again the ref catalog from file:\n",
    "ref_catalog = astropy.table.Table.read(photometry_dir / f\"ref_catalog_{object_to_process}.fits\")\n",
    "\n",
    "\n",
    "n_files = len(science_files.summary)\n",
    "# And now we loop over all selected exposures:\n",
    "for (i, science_file) in enumerate(science_files.files):\n",
    "\n",
    "    #if i < 104: # could use something like that to relaunch on selected files\n",
    "    #    continue\n",
    "    \n",
    "    image_filename = Path(science_file).stem\n",
    "    print(f\"=== Processing image {i+1}/{n_files}: {image_filename} ===\")\n",
    "\n",
    "    image = ccdproc.CCDData.read(science_file)\n",
    "\n",
    "    # We build a dict containing some meta-information of the image taken from the FITS header.\n",
    "    # We'll later write this as meta-information of the catalogue.\n",
    "    meta_from_image = {key: image.header[key] for key in [\n",
    "        \"DATE-OBS\", \"EXPTIME\", \"IMAGETYP\", \"AIRMASS\", \"PIERSIDE\", \"FILTER\", \"OBJECT\",\n",
    "        \"FOCUSPOS\", \"FOCTEMP\", \"RA\", \"DEC\", \"SET-TEMP\", \"CCD-TEMP\", \"GAIN\", \"OFFSET\"\n",
    "        ]}\n",
    "    \n",
    "    # Now run the measurements:\n",
    "    catalog = measure_photometry(image, ref_catalog[\"sky_centroid_win\"])\n",
    "\n",
    "    # Add the information from the FITS header\n",
    "    catalog.meta.update(meta_from_image)\n",
    "\n",
    "    # Copy a few columns from the reference catalog\n",
    "    #catalog[\"sky_centroid_win\"] = ref_catalog[\"sky_centroid_win\"]\n",
    "\n",
    "    # And write all this as a FITS table\n",
    "    catalog.write(photometry_dir / f\"{image_filename}.fits\", overwrite=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datared2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

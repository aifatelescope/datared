{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometry\n",
    "\n",
    "On this page we'll detect sources and perform simple aperture photometry (along other measurements) for each pre-reduced image.\n",
    "The same procedure could of course also be applied to coadded images.\n",
    "\n",
    "As before, you could copy or write the code shown below in a script, or alternatively directly download this page as a {download}`jupyter notebook <./photometry.ipynb>` file.\n",
    "\n",
    "To run the code, you'll need the module `dataredconfig.py`, as explained [here](./data.md).\n",
    "\n",
    "```{note}\n",
    "The photometry presented here is sufficient for our purposes, but remains extremely simple. Notably, it ignores the effect of variable seeing (in time and/or accross filters). The next steps to improve upon the minimal approach shown here would be to perform a PSF homogeneization or to use PSF-fitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataredconfig\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import astropy\n",
    "import astropy.visualization\n",
    "from astropy import units as u\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ccdproc\n",
    "import photutils.background\n",
    "import photutils.aperture\n",
    "import photutils.segmentation\n",
    "import photutils.psf\n",
    "\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll ignore some astropy warnings that get raised as our FITS headers (from NINA) are not 100% standards compliant.\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=astropy.wcs.FITSFixedWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting the correct path to the pre-reduced science frames to work on:\n",
    "#science_files_dir = dataredconfig.work_dir / \"LIGHT_PRERED\" # In case astrometric calibration was already performed before the pre-reduction\n",
    "science_files_dir = dataredconfig.work_dir / \"ASTROMETRY\"\n",
    "science_files = ccdproc.ImageFileCollection(science_files_dir, keywords=dataredconfig.ifc_header_keywords)\n",
    "\n",
    "# Where to write the catalogs:\n",
    "photometry_dir = dataredconfig.work_dir / \"PHOTOMETRY\"\n",
    "photometry_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Overview of all available files:\n",
    "science_files.summary\n",
    "# You may want to try this instead, for a better display:\n",
    "#science_files.summary.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: selecting the science frames to run on : \n",
    "object_to_process = \"HD92670\"\n",
    "\n",
    "science_files = science_files.filter(object=object_to_process)\n",
    "\n",
    "#science_files.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will measure photometry on all these files.\n",
    "But we start by picking one reference image, used to detect sources and to check the overall procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image_filepath = science_files.files[0]\n",
    "ref_image = ccdproc.CCDData.read(ref_image_filepath)\n",
    "\n",
    "if(ref_image.wcs is None): # Performing forced photometry requires each frame to have a good WCS. This test is just to avoid obvious mistakes.\n",
    "    raise RuntimeError(\"The image has no WCS, make sure you specify the correct directory (i.e., with WCS) above!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating and subtracting the background\n",
    "\n",
    "Some of the following tasks will be run on several images, and we therefore define them as very simple functions.\n",
    "Of course, depending on the data to be processed, you might want to adjust (hard-coded) parameters in these functions. They are only provided as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_background(image):\n",
    "    \"\"\"Function to estimate the background (in form of an image),\n",
    "    and the root-mean-square deviation (RMS) of the background.\n",
    "    \n",
    "    Parameters:\n",
    "    image: a CCDData object\n",
    "\n",
    "    Returns:\n",
    "    background, background_rms: two numpy arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    bkg = photutils.background.Background2D(\n",
    "        image.data,\n",
    "        box_size=(500, 500),\n",
    "        filter_size=(3, 3),\n",
    "        bkg_estimator=photutils.background.MedianBackground())\n",
    "    \n",
    "    return bkg.background, bkg.background_rms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run this on the reference image\n",
    "background, background_rms = estimate_background(ref_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the background image\n",
    "plt.figure()\n",
    "plt.imshow(background, origin='lower', cmap='Greys_r', interpolation='nearest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We subtract the background from the reference image\n",
    "ref_image_noback = ref_image.subtract(ccdproc.CCDData(background, unit=\"adu\"))\n",
    "\n",
    "# And we define a \"threshold\" image for this reference frame,\n",
    "# whose values are multiples of the estimated RMS of the background in each pixel.\n",
    "# (RMS is an estimate of the standard deviation, so 3*RMS is \"3 sigma\" above the background)\n",
    "threshold = 3.0 * background_rms # this is an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source detection and measurement\n",
    "\n",
    "We now detect sources (as groups of connected pixels above the threshold) and measure their exact positions (among other parameters), on the selected reference image. Let's nevertheless group all this in a function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_measure(image, threshold):\n",
    "    \"\"\"Function to detect and measure sources.\n",
    "    This is close to what Source Extractor typically does.\n",
    "    \n",
    "    Parameters:\n",
    "    image: a CCDData object\n",
    "    threshold: a 2D-array with threshold values\n",
    "\n",
    "    Returns:\n",
    "    An Astropy Table with source positions (from  windowed centroids, \n",
    "    both in pixel and sky coordinates) and other measurements.\n",
    "    \"\"\"\n",
    "    data = image.data \n",
    "\n",
    "    # Filtering (convolving with a 2D Gaussian) for better source detection\n",
    "    kernel = photutils.segmentation.make_2dgaussian_kernel(fwhm=4.0, size=21)  # FWHM in pixels\n",
    "    convolved_data = astropy.convolution.convolve(data, kernel)\n",
    "\n",
    "    # Segmenting the image\n",
    "    finder = photutils.segmentation.SourceFinder(npixels=4, connectivity=4, progress_bar=False)\n",
    "    segment_map = finder(convolved_data, threshold)\n",
    "    #segment_map = finder(data, threshold) # One could also run this on the unfiltered image\n",
    "\n",
    "    # And measuring sources\n",
    "    source_catalog = photutils.segmentation.SourceCatalog(data, segment_map, convolved_data=convolved_data, wcs=image.wcs)\n",
    "    source_table = source_catalog.to_table(\n",
    "        columns=[\"xcentroid_win\", \"ycentroid_win\", \"sky_centroid_win\",\n",
    "                 \"fwhm\", \"max_value\", \"kron_flux\", \"segment_flux\", \"segment_area\"]\n",
    "        )\n",
    "\n",
    "    return astropy.table.Table(source_table) # We convert the QTable to a Table, better for later FITS writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this on the reference image\n",
    "ref_catalog = detect_and_measure(ref_image_noback, threshold)\n",
    "\n",
    "print(f\"Reference catalog: {len(ref_catalog)} sources detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running a detection, it's almost mandatory to check the result with a visualization! We do this with the following interactive Figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure that overplots the image and the positions of the detected sources\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(projection=ref_image_noback.wcs)\n",
    "ax.imshow(ref_image_noback.data, origin='lower', cmap='Greys_r', interpolation='nearest',\n",
    "    norm=astropy.visualization.simple_norm(ref_image_noback.data, stretch=\"log\", vmin=-20, vmax=2000))\n",
    "ax.scatter(\n",
    "    ref_catalog[\"xcentroid_win\"],\n",
    "    ref_catalog[\"ycentroid_win\"],\n",
    "    transform=ax.get_transform('pixel'),\n",
    "    s=50, # The size of these markers is not related to any measurement apertures!\n",
    "    edgecolor='red', facecolor='none'\n",
    "    )\n",
    "ax.grid(color='white', ls='solid')\n",
    "ax.set_xlabel('RA')\n",
    "ax.set_ylabel('Dec')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in and check if all relevant sources are detected. If there are issues, one might have to adjust the sensitivity of the detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this catalog smaller, for testing:\n",
    "ref_catalog = ref_catalog[ref_catalog[\"kron_flux\"] > 10000] # pick the brightest sources\n",
    "len(ref_catalog)\n",
    "\n",
    "# Rerun the vizualisation above to see the effect..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note} \n",
    "A large reference catalog will slow down the photometry. It's helpful to adapt the flux threshold above to keep mainly those stars you actually care about, and not every tiny detection.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, we write the reference catalog in this directory.\n",
    "# It contains the aperture positions.\n",
    "ref_catalog.write(photometry_dir / f\"ref_catalog_{object_to_process}.fits\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forced aperture photometry\n",
    "\n",
    "We'll now perform forced aperture photometry on all science images of our target, with a series of aperture sizes (radii given in arcseconds in the code below).\n",
    "This means that we use the sky coordinates of the sources detected in the reference frame to place the same apertures on all dithered exposures of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We group all steps of the photometric measurement into one function:\n",
    "\n",
    "def measure_photometry(image, sky_positions, run_simple_fit=False):\n",
    "    \"\"\"Function for forced aperture photometry given the provided sky_positions.\n",
    "    This function first estimates and subtracts the background from the image,\n",
    "    and performs aperture photometry both on the background-subtracted image and on the background alone.\n",
    "\n",
    "    Parameters:\n",
    "    image: a CCDData object\n",
    "    sky_positions: a list or column of aperture positions, in sky coordinates (i.e. as SkyCoord objects)\n",
    "    run_fit: if True, a simple 2D Gaussian fit is also run, providing FWHM and flux measurements. Take significantly more time.\n",
    "\n",
    "    Returns:\n",
    "    An Astropy Table with measurements for several aperture radii at the given positions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Estimating and subtracting the background:\n",
    "    tstart = time()    \n",
    "    background, _ = estimate_background(image)\n",
    "    image_noback = image.subtract(ccdproc.CCDData(background, unit=\"adu\"))\n",
    "    tend = time()\n",
    "    print(f\"Background subtraction took {tend-tstart:.2f} sec\")\n",
    "    \n",
    "    \n",
    "    # Aperture photometry\n",
    "    aperture_radii = [4, 6, 8, 10] # In arcsec\n",
    "    tstart = time()\n",
    "    # We generate a separate catalog for each aperture radius, and combine these afterwards\n",
    "    aperture_catalogs = []\n",
    "    for r in aperture_radii:\n",
    "\n",
    "        apertures = photutils.aperture.SkyCircularAperture(sky_positions, r=r*u.arcsec)\n",
    "\n",
    "        # Photometry on the background-subtracted image:\n",
    "        aperture_measurements = photutils.aperture.ApertureStats(image_noback.data, aperture=apertures, wcs=image_noback.wcs)\n",
    "        # Same photometry on the background image:\n",
    "        background_aperture_measurements = photutils.aperture.ApertureStats(background.data, aperture=apertures, wcs=image_noback.wcs)\n",
    "        \n",
    "        aperture_catalog = aperture_measurements.to_table(columns=[\"sum\"])\n",
    "        background_aperture_catalog = background_aperture_measurements.to_table(columns=[\"sum\"])\n",
    "\n",
    "        # Note: ApertureStats also provides \"fwhm\" and \"elongation\", among other stats.\n",
    "        # While these measurements are fast and can be useful, they are computed from unweighted moments,\n",
    "        # and will therefore be strongly influenced by the aperture size and the noise.\n",
    "        # Just for reference, this is how to get them:\n",
    "        #aperture_catalog = aperture_measurements.to_table(columns=[\"fwhm\", \"elongation\", \"sum\"])        \n",
    "\n",
    "        # Rename columns by adding the aperture radius, to get for example \"sum_4\" instead of sum\n",
    "        for name in aperture_catalog.colnames:\n",
    "            aperture_catalog.rename_column(name, new_name=f\"{name}_{str(r)}\")\n",
    "        for name in background_aperture_catalog.colnames:\n",
    "            background_aperture_catalog.rename_column(name, new_name=f\"back_{name}_{str(r)}\")\n",
    "         \n",
    "        aperture_catalogs.append(aperture_catalog)\n",
    "        aperture_catalogs.append(background_aperture_catalog)\n",
    "    \n",
    "    # And now merge these catalogs into a single one:\n",
    "    merged_catalog = astropy.table.hstack(aperture_catalogs,\n",
    "        join_type=\"exact\", metadata_conflicts=\"silent\"\n",
    "        )\n",
    "    tend = time()\n",
    "    print(f\"Photometry took {tend-tstart:.2f} sec\")\n",
    "\n",
    "\n",
    "    # Optional simple 2D Gaussian fit for FWHM-measurement of sources:\n",
    "    if run_simple_fit:\n",
    "        tstart = time() \n",
    "        # Compute pixel-coordinate positions of the positions:\n",
    "        image_pixel_positions = astropy.wcs.utils.skycoord_to_pixel(sky_positions, ref_image.wcs)\n",
    "        xypos = np.array(image_pixel_positions).transpose() # Rearranging the data\n",
    "        # Perform the fitting:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            fit_catalog = photutils.psf.fit_2dgaussian(image_noback.data, xypos=xypos, fit_shape=15, fwhm=6, fix_fwhm=False).results\n",
    "        # Copy over some relevant columns into our final catalog:\n",
    "        merged_catalog[\"fwhm_fit\"] = fit_catalog[\"fwhm_fit\"] # The FWHM obtained form the fit, in pixels\n",
    "        merged_catalog[\"flux_fit\"] = fit_catalog[\"flux_fit\"] # The flux from the fit, in ADU\n",
    "        merged_catalog[\"q_fit\"] = fit_catalog[\"qfit\"] # A quality-of-fit metric, see doc of photutils.psf for details.\n",
    "        tend = time()\n",
    "        print(f\"2D Gaussian fitting took {tend-tstart:.2f} sec\")\n",
    "\n",
    "    return merged_catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# As a test, we run this on the ref_image.\n",
    "# For this we read the ref image again, as the one in memory already has the background subtracted.\n",
    "ref_image = ccdproc.CCDData.read(ref_image_filepath)\n",
    "ref_photo_cat = measure_photometry(ref_image, ref_catalog[\"sky_centroid_win\"], run_simple_fit=True)\n",
    "print(ref_photo_cat.colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chimney Plot\n",
    "As an illustration of how this photometric catalog can be used, we create a basic and very common scatter plot: the so-called \"chimney plot\", named after its shape. The plot shows instrumental magnitude against FWHM (or some other size measurement) of all detected sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as an example, let's use the flux within the apertures of 6 arcseconds: \n",
    "ref_photo_cat[\"mag_6\"] = -2.5 * np.log10(ref_photo_cat[\"sum_6\"].value)\n",
    "\n",
    "# We create a scatter plot of FWHM versus mag, and color the datapoints according to the q_fit parameter (see legend).\n",
    "# High values of q_fit indicate that the source was not well fitted by the simple 2D-Gaussian.\n",
    "plt.figure()\n",
    "plt.scatter(\n",
    "    ref_photo_cat[\"fwhm_fit\"].value, \n",
    "    ref_photo_cat[\"mag_6\"], \n",
    "    c=ref_photo_cat[\"q_fit\"].value,\n",
    "    vmin=0.0, vmax=0.5,\n",
    "    cmap=\"jet\",\n",
    "    s=10\n",
    ")\n",
    "plt.gca().invert_yaxis() # Bright is at the top!\n",
    "plt.colorbar(label=\"Fit quality metric: sum(abs(fit residuals)) / (fitted flux)\")\n",
    "plt.xlabel(\"FWHM [pix]\")\n",
    "plt.xlim(0, 15)\n",
    "plt.ylabel(\"Instrumental magnitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the measurements on all images \n",
    "\n",
    "Finally, we apply this measurement function to all images of the object.\n",
    "\n",
    "If you don't need the Gaussian fitting, you can run this faster by setting `run_simple_fit=False` below, in the call of `measure_photometry()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read again the ref catalog from file:\n",
    "ref_catalog = astropy.table.Table.read(photometry_dir / f\"ref_catalog_{object_to_process}.fits\")\n",
    "\n",
    "\n",
    "n_files = len(science_files.summary)\n",
    "# And now we loop over all selected exposures:\n",
    "for (i, science_file) in enumerate(science_files.files):\n",
    "\n",
    "    #if i < 104: # could use something like that to relaunch on selected files\n",
    "    #    continue\n",
    "    \n",
    "    image_filename = Path(science_file).stem\n",
    "    print(f\"=== Processing image {i+1}/{n_files}: {image_filename} ===\")\n",
    "\n",
    "    image = ccdproc.CCDData.read(science_file)\n",
    "\n",
    "    # We build a dict containing some meta-information of the image taken from the FITS header.\n",
    "    # We'll later write this as meta-information of the catalogue.\n",
    "    meta_from_image = {key: image.header[key] for key in [\n",
    "        \"DATE-OBS\", \"EXPTIME\", \"IMAGETYP\", \"AIRMASS\", \"PIERSIDE\", \"FILTER\", \"OBJECT\",\n",
    "        \"FOCUSPOS\", \"FOCTEMP\", \"RA\", \"DEC\", \"SET-TEMP\", \"CCD-TEMP\", \"GAIN\", \"OFFSET\"\n",
    "        ]}\n",
    "    \n",
    "    # Now run the measurements:\n",
    "    catalog = measure_photometry(image, ref_catalog[\"sky_centroid_win\"], run_simple_fit=True)\n",
    "\n",
    "    # Add the information from the FITS header\n",
    "    catalog.meta.update(meta_from_image)\n",
    "\n",
    "    # Could copy a few columns from the reference catalog\n",
    "    # But no need to do this here: we keep the reference catalog, and will use it later. \n",
    "    #catalog[\"sky_centroid_win\"] = ref_catalog[\"sky_centroid_win\"]\n",
    "\n",
    "    # And write all this as a FITS table\n",
    "    catalog.write(photometry_dir / f\"{image_filename}.fits\", overwrite=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datared2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

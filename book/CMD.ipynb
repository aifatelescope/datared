{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour Magnitude Diagram\n",
    "\n",
    "```{warning}\n",
    "This page is still under construction. It will be ready in time for the S263 data reduction sessions.\n",
    "```\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- read the photometric catalogs of the science frames and group them in a convenient structure,\n",
    "- calibrate the photometry by comparing our instrumental magnitudes to apparent magnitudes from a reference catalogue,\n",
    "- draw a colour-magnitude diagram (CMD),\n",
    "- and compare this CMD to isochrones from a stellar evolution code.\n",
    "\n",
    "\n",
    "You can download this page as a {download}`jupyter notebook <./CMD.ipynb>` file.\n",
    "\n",
    "```{note}\n",
    "In case you have been working on an AIfA lab room computer until this point, you might be interested in moving to a personal laptop (for example) for these last steps.\n",
    "All that we'll need from here on is the content of the `PHOTOMETRY` directory (including the reference catalog). This is a relatively small amount of data (compared to the raw or pre-reduced images), so you could consider transferring just these files to your own computer. The CPU requirements for these last steps will also be negligible. Make sure to install the right python environment, following [](./installation.md). There is no need for `astrometry.net` at this stage.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataredconfig\n",
    "\n",
    "import numpy as np\n",
    "import astropy\n",
    "import astropy.table\n",
    "import astropy.visualization\n",
    "import astropy.coordinates\n",
    "\n",
    "import astroquery.vizier\n",
    "\n",
    "import urllib.request\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "from astropy import units as u\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.widgets\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering and structuring the data\n",
    "\n",
    "We start by reading the relevant catalogs as a list of tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the photometry catalogs are:\n",
    "photometry_dir = dataredconfig.work_dir / \"PHOTOMETRY\"\n",
    "\n",
    "object_to_process = \"M 37\"\n",
    "\n",
    "catalog_filepaths = sorted(list(photometry_dir.glob('*.fits')))\n",
    "catalogs = []\n",
    "\n",
    "for catalog_filepath in catalog_filepaths:\n",
    "    \n",
    "    catalog = astropy.table.Table.read(catalog_filepath)\n",
    "\n",
    "    # We select the photometric catalogs of our object:  \n",
    "    if \"OBJECT\" in catalog.meta:\n",
    "        if catalog.meta[\"OBJECT\"] == object_to_process:\n",
    "            print(f\"{catalog_filepath} : {catalog.meta}\")\n",
    "            catalogs.append(catalog)\n",
    "\n",
    "print(f\"Collected {len(catalogs)} catalogs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we \"merge\" all these separate tables into a particular structure that will be very useful.\n",
    "\n",
    " * Measurements done with the same filter are stacked in \"depth\", i.e., grouped in 2D-columns.\n",
    " * Finally all filters are stacked \"horizontally\", i.e., as separate columns in one single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_names = (\"g\", \"r\", \"i\")\n",
    "filter_catalogs = []\n",
    "\n",
    "for filter_name in filter_names:\n",
    "    #print(f\"Starting filter {filter_name}\")\n",
    "    this_filter_catalogs = [catalog for catalog in catalogs if catalog.meta[\"FILTER\"] == filter_name]\n",
    "    this_filter_catalog = astropy.table.dstack(this_filter_catalogs, join_type=\"exact\", metadata_conflicts=\"silent\")\n",
    "    this_filter_catalog.name = filter_name\n",
    "    \n",
    "    filter_catalogs.append(this_filter_catalog)\n",
    "\n",
    "# And we stack these catalogs horizontally into one single table:\n",
    "cat = astropy.table.hstack(filter_catalogs,\n",
    "        join_type=\"exact\", metadata_conflicts=\"silent\",\n",
    "        table_names=filter_names, uniq_col_name='{col_name}_{table_name}'\n",
    "        )\n",
    "\n",
    "# The columns are now the following:\n",
    "print(\"Columns of cat:\")\n",
    "for colname in cat.colnames:\n",
    "    print(f\"{colname}: shape {cat[colname].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the filter name is now appended to the column names.\n",
    "These columns have two dimension: the first index identifies the source (i.e., star), and the second index runs over the different exposures.\n",
    "\n",
    "We now add two more columns: the sky position of each star, and while we are at it the separation between the star and the cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the position, we need to read the reference catalog:\n",
    "ref_catalog = astropy.table.Table.read(photometry_dir / f\"ref_catalog_{object_to_process}.fits\")\n",
    "assert len(ref_catalog) == len(cat) # Just a check that these are indeed of same length\n",
    "    \n",
    "cat[\"sky_pos\"] = ref_catalog[\"sky_centroid_win\"]\n",
    "target_center_pos = astropy.coordinates.SkyCoord(cat.meta[\"RA\"]*u.deg, cat.meta[\"DEC\"]*u.deg)\n",
    "cat[\"separation\"] = target_center_pos.separation(cat[\"sky_pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick CMD in instrumental magnitudes\n",
    "\n",
    "As an example about how the catalog can now be used, we compute a median instrumental magnitude in each filter (where the median is taken over the different exposures) and plot a simple uncalibrated CMD.\n",
    "This quick magnitude computation can certainly be improved, in particular if the atmospheric conditions changed during the observation! We'll come back to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We take the median accross \"axis=1\", that is the second index\n",
    "# (the first index (axis=0) identifies the different stars).\n",
    "# Note that the aperture radius of 4 arcsec is just used here as an example, other radii might perform better!\n",
    "cat[\"quick_instr_mag_g\"] = np.median(-2.5 * np.log10(cat[\"sum_4_g\"].value), axis=1)\n",
    "cat[\"quick_instr_mag_r\"] = np.median(-2.5 * np.log10(cat[\"sum_4_r\"].value), axis=1)\n",
    "cat[\"quick_instr_mag_i\"] = np.median(-2.5 * np.log10(cat[\"sum_4_i\"].value), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a first CMD\n",
    "plt.figure()\n",
    "plt.scatter(\n",
    "    cat[\"quick_instr_mag_g\"] - cat[\"quick_instr_mag_i\"],\n",
    "    cat[\"quick_instr_mag_r\"],\n",
    "    s = 5,\n",
    "    c = cat[\"separation\"].value # color represents separation between star and cluster center\n",
    ")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label=f\"Separation to target center in {cat['separation'].unit}\")\n",
    "plt.xlabel(\"Instrumental mag g - i\")\n",
    "plt.ylabel(\"Instrumental mag r\")\n",
    "plt.title(object_to_process)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude calibration\n",
    "\n",
    "To compare our data with stellar models, we need to:\n",
    "\n",
    "- convert our instrumental magnitudes into apparent magnitudes (that is, \"standardise\" our observations)\n",
    "- correct the absolute magnitudes of the stellar models by some appropriate distance and extinction, so that they can be compared to apparent magnitudes.\n",
    "\n",
    "In this section we will start by calibrating our magnitude measurements. We do this by matching some of the measured stars with a reference catalogue.\n",
    "\n",
    "As a preparatory task, we compute instrumental magnitudes for each flux measurement, so that we can process each exposure individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing instrumental magnitudes for all apertures and exposures:\n",
    "filter_names = [\"g\", \"r\", \"i\"]\n",
    "photometry_prefixes = [\"sum_4\", \"sum_6\", \"sum_8\", \"sum_10\", \"flux_fit\"]\n",
    "for filter_name in filter_names:\n",
    "    for photometry_prefix in photometry_prefixes:\n",
    "        cat[f\"instr_mag_{photometry_prefix}_{filter_name}\"] = -2.5 * np.log10(cat[f\"{photometry_prefix}_{filter_name}\"].value)\n",
    "        # Recall that these are 2D-columns with indices (source, exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching to a reference catalogue\n",
    "\n",
    "We will make use the catalogue ATLAS-REFCAT2. This is an all-sky reference catalog compiling together several large surveys. In particular, among many other data, it contains *real* photometry in the SDSS filters g, r, and i for stars brighter than the 14th magnitude. Details about the catalogue can be found at https://archive.stsci.edu/hlsp/atlas-refcat2 .\n",
    "\n",
    "We access this catalogue via a service called VizieR, a library of published astronomical catalogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizier =  astroquery.vizier.Vizier()\n",
    "vizier.ROW_LIMIT = 500 # just as a safety measure, 500 is more than enough\n",
    "\n",
    "catalogue_list = vizier.find_catalogs('ATLAS-REFCAT2')\n",
    "print(\"Identified catalogues:\")\n",
    "for k, v in catalogue_list.items(): \n",
    "    print(k, \":\", v.description)\n",
    "\n",
    "ref_cat_name = list(catalogue_list.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the reference catalogue within 20 arcmin around the target, and down to mag 13:\n",
    "ref_cat = vizier.query_region(target_center_pos, radius=20*u.arcmin, catalog=ref_cat_name, column_filters={'rmag': '<13'})[0]\n",
    "print(ref_cat.colnames)\n",
    "print(ref_cat)\n",
    "\n",
    "# If you obtain 500 stars (i.e., the ROW_LIMIT), decrease the depth of the request (see column_filters in the above).\n",
    "# We really don't need more than a few stars, in fact!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching our own catalogue with the reference catalogue\n",
    "\n",
    "# The coordinates to match:\n",
    "ref_cat_coords = astropy.coordinates.SkyCoord(ra=ref_cat[\"RA_ICRS\"], dec=ref_cat[\"DE_ICRS\"])\n",
    "cat_coords = cat[\"sky_pos\"]\n",
    "\n",
    "# The matching itself is just one call:\n",
    "idx, seps, _ = astropy.coordinates.match_coordinates_sky(cat_coords, ref_cat_coords)\n",
    "\n",
    "# This returns:\n",
    "# idx: indices into ref_cat_coords to get the matched points for each cat_coords. Shape matches cat_coords.\n",
    "# seps: on-sky separation between the closest match for each cat_coords and the cat_coords. Shape matches cat_coords.\n",
    "\n",
    "# And assembling a combined matched catalogue:\n",
    "sep_constraint = seps < 2.0 * u.arcsec\n",
    "cat_matches = cat[sep_constraint]\n",
    "ref_cat_matches = ref_cat[idx[sep_constraint]]\n",
    "\n",
    "matched_cat = astropy.table.hstack([cat_matches, ref_cat_matches], join_type=\"exact\", metadata_conflicts=\"silent\")\n",
    "\n",
    "print(\"Column names of matched catalogue:\")\n",
    "print(matched_cat.colnames)\n",
    "print(f\"Length of matched catalogue: {len(matched_cat)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the histogram of separations between the matches, i.e., between the stars from the reference catalogue that are nearest to the sources from our own catalogue. The typical astrometric error should be much smaller than a pixel, if our astrometric calibration is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of separations:\n",
    "plt.figure()\n",
    "plt.hist(seps.to_value(u.arcsec), bins=50, range=(0, 2))\n",
    "plt.xlabel(\"Separation in arcseconds\")\n",
    "plt.title(\"Histogram of on-sky separation between matches\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the magnitude zero points\n",
    "\n",
    "Using the matched catalogue,  we can visualize the difference between our own instrumental magnitudes and the apparent magnitudes from the reference catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_to_show = 0 # Showing data from the first exposure in each filter\n",
    "photom_prefix_to_show = \"sum_4\" # Showing data for the 4-arcsec aperture\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(matched_cat[\"rmag\"], matched_cat[f\"instr_mag_{photom_prefix_to_show}_g\"][:,exp_to_show] - matched_cat[\"gmag\"], ls=\"None\", marker=\".\", label=\"g\", color=\"green\")\n",
    "plt.plot(matched_cat[\"rmag\"], matched_cat[f\"instr_mag_{photom_prefix_to_show}_r\"][:,exp_to_show] - matched_cat[\"rmag\"], ls=\"None\", marker=\".\", label=\"r\", color=\"orange\")\n",
    "plt.plot(matched_cat[\"rmag\"], matched_cat[f\"instr_mag_{photom_prefix_to_show}_i\"][:,exp_to_show] - matched_cat[\"imag\"], ls=\"None\", marker=\".\", label=\"i\", color=\"red\")\n",
    "plt.xlabel(\"Apparent magnitude from reference catalogue\")\n",
    "plt.ylabel(f\"instr_mag_{photom_prefix_to_show} - apparent mag\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we compute a zeropoint for each filter, exposure, and aperture size, and apply these to our full catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filter_name in filter_names:\n",
    "    for photometry_prefix in photometry_prefixes:\n",
    "        \n",
    "        # Computing the zeropoint in the catalogue \"mached_cat\"\n",
    "        # The zeropoint is computed as the median (across all sources) of the mag differences plotted above.\n",
    "        # For this we'll need to manually \"broadcast\" the reference mag column, as it is 1D.\n",
    "\n",
    "        instr_mags = matched_cat[f\"instr_mag_{photometry_prefix}_{filter_name}\"] # This is 2D\n",
    "        ref_mags = np.tile(matched_cat[f\"{filter_name}mag\"], (instr_mags.shape[1], 1)).transpose() # This is now also 2D, same shape\n",
    "        #ref_mags = np.repeat(np.atleast_2d(matched_cat[f\"{filter_name}mag\"]), instr_mags.shape[1], axis=0).transpose() # Equivalent, not much nicer\n",
    "\n",
    "        zeropoints = np.ma.median(instr_mags - ref_mags, axis=0) # Median taken accross the first dim, i.e. the sources\n",
    "        # This contains one zeropoint per exposure\n",
    "\n",
    "        # And now we directly apply those zero points in the catalogue \"cat\"\n",
    "        cat[f\"mag_{photometry_prefix}_{filter_name}\"] = cat[f\"instr_mag_{photometry_prefix}_{filter_name}\"] - zeropoints\n",
    "\n",
    "        # To get one single magnitude per star, we compute the median (across exposures) of the calibrated magnitudes:\n",
    "        cat[f\"median_mag_{photometry_prefix}_{filter_name}\"] = np.ma.median(cat[f\"mag_{photometry_prefix}_{filter_name}\"], axis=1)\n",
    "\n",
    "        # Note that this last step can certainly be improved, for example with a weighted average and outlier rejection.\n",
    "        # The above provides a simple and robust first solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the CMD plot with these new calibrated apparent magnitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calibrated observational CMD\n",
    "plt.figure()\n",
    "plt.scatter(\n",
    "    cat[\"median_mag_sum_4_g\"] - cat[\"median_mag_sum_4_i\"],\n",
    "    cat[\"median_mag_sum_4_r\"],\n",
    "    s = 5,\n",
    "    c = cat[\"separation\"].value # color represents separation between star and cluster center\n",
    ")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label=f\"Separation to target center in {cat['separation'].unit}\")\n",
    "plt.xlabel(\"g - i\")\n",
    "plt.ylabel(\"r\")\n",
    "plt.title(object_to_process)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isochrones\n",
    "\n",
    "We will use isochrones (i.e. \"synthetic\" cluster CMDs) based on the stellar evolution code MESA, as provided by the [MIST](https://waps.cfa.harvard.edu/MIST/) project ([Dotter 2016](http://adsabs.harvard.edu/abs/2016ApJS..222....8D) and [Choi et al. 2016](http://adsabs.harvard.edu/abs/2016ApJ...823..102C)). These isochrones have been generated with synthetic photometry computed in the same Sloan/SDSS photometric system that we use for our observations.\n",
    "To make the use of these isochrones as easy as possible, we have repackaged them into a custom single file, that we will download and use below.\n",
    "\n",
    "In case you want to know more about the origin of these isochrones, see the website of MIST (https://waps.cfa.harvard.edu/MIST/), the website of MESA (https://mesastar.org),  and the related publications.\n",
    "\n",
    "The details about our repackaging into a single file are given [in this notebook](./MIST_isochrone_repackaging.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file containing all the isochrones (about 48 MB):\n",
    "isochrones_url = \"https://uni-bonn.sciebo.de/s/czdMPjrLyi571uu/download\"\n",
    "local_isochrones_filepath = pathlib.Path(\"isochrones_MIST.pickle\")\n",
    "if not local_isochrones_filepath.exists():\n",
    "    urllib.request.urlretrieve(isochrones_url, local_isochrones_filepath)\n",
    "\n",
    "# Read this file with the following code (see below for explanations):\n",
    "with open(local_isochrones_filepath, 'rb') as f:\n",
    "    (isochrones, vrots, metallicities, logages) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of this data needs a few explanations.\n",
    "\n",
    "In practice, a single isochrone is stored as a 2D table: columns are absolute magnitudes in g, r, i, and rows correspond to different initial stellar masses. One can compute differences between these columns to obtain colors.\n",
    "\n",
    "Obviously we need several isochrones. So we have such a table for several different ages, for several different metallicities, and for two stellar rotation velocities (more precisely: with or without rotation). Note that these isochrone tables don't necessarily have the same size (i.e., the same resolution of initial masses).\n",
    "\n",
    "The contents read by the code above are the following:\n",
    "\n",
    "- `isochrones` is a nested list (i.e., a list of lists of lists) of astropy Tables containing the isochrones.\n",
    "    - The **first** index of `isochrones` corresponds to the stellar rotation velocity, \n",
    "    - the **second** index corresponds to metallicity, and\n",
    "    - the **third** index corresponds to the age.\n",
    "    - Then, the contained astropy tables have 4 columns, named `g`, `r`, `i`, and `initial_mass`, where the photometry is given in absolute magnitudes, and the initial mass is given in solar masses.\n",
    "- `vrots` is a 1D numpy array containing stellar rotation velocities (**first** index of `isochrones`). In fact, there are just two values: 0.0 means no rotation, and 0.4 means that the initial rotation velocity of higher mass stars is set to 0.4 times a critical surface velocity.\n",
    "- `metallicities` is a 1D numpy array with the different available metallicities ([Fe/H]) of the isochrones, corresponding to the **second** index of `isochrones`. Recall that the metallicity of stars, i.e., the abundance of elements other than hydrogen and helium, has a significant influence on stellar evolution, and that we can assume that stars of a cluster share the same metallicity. Metallicity is often described by the logarithm of the iron-to-hydrogen ratio relative to that of the Sun, and denoted [Fe/H]. For example, [Fe/H] = 0 means that the stars have the same metallicity as the Sun, while [Fe/H] = -1.0 means that their metallictiy is one tenth that of the Sun.\n",
    "- `logages` is a 1D numpy array containing the log10 of the available ages (in years) of the isochrones, corresponding to the **third** index of `isochrones`.\n",
    "\n",
    "\n",
    "The following plot demonstrates how to use the objects read from the isochrone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating the use of the isochrones with a simple non-interactive plot\n",
    "\n",
    "vrot_index = 0\n",
    "metallictiy_index = 12\n",
    "age_indices_to_plot = [60, 70, 80]\n",
    "\n",
    "plt.figure()\n",
    "for age_index in age_indices_to_plot:\n",
    "\n",
    "    age = 10.0**logages[age_index]\n",
    "    metallicity = metallicities[metallictiy_index]\n",
    "    vrot = vrots[vrot_index]\n",
    "\n",
    "    label_string = f\"{age/1e9:.2f} Gyr\"\n",
    "\n",
    "    # And this is how to get one of the isochrones:\n",
    "    iso = isochrones[vrot_index][metallictiy_index][age_index]\n",
    "\n",
    "    plt.plot(iso[\"r\"] - iso[\"i\"], iso[\"r\"], label=label_string)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Absolute mag r - absolute mag i\")\n",
    "plt.ylabel(\"Absolute magnitude r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extinction and distance\n",
    "\n",
    "To compare these isochrones to our calibrated data, we need two more ingredients: extinction, and distance.\n",
    "\n",
    "Extinction is the radiation loss due to scattering and absorption by the interstellar medium (gas and dust). For a given line of sight, the amount of extinction depends on wavelength: blue light is scattered and absorbed more than red light, causing *reddening* of the light of stars. This dependency on wavelength is called a *reddening law*. Its shape depends on the properties of the interstellar medium, and is *not* the same for every cluster or part of the sky. The relation that we'll use below is an empirical \"average\" solution, certainly only approximate, but it illustrates the idea.\n",
    "\n",
    "Note that extinction is multiplicative in flux, and in practice it can therefore be expressed as a magnitude offset $A$ for each band (assuming some spectrum for the starlight). These magnitude offsets in the different bands are proportional to each other. For a given reddening law, they can be expressed as multiples of the extinction in some reference band. In the example below, this reference is the visible band V, and the reference extinction is denoted $A_{\\mathrm{V}}$. We will use it as a free parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extinction_law(A_V):\n",
    "    \"\"\"\n",
    "    Returns extinction values for the different SDSS/Sloan filters, based on some reference total extinction A_V\n",
    "\n",
    "    The particular values we use here are from Wang and Chen (2019) ApJ 877 116:\n",
    "    https://iopscience.iop.org/article/10.3847/1538-4357/ab1c61\n",
    "    \"\"\"\n",
    "    #return {\"g\": ref_ext*3.30, \"r\": ref_ext*2.31, \"i\":ref_ext*1.71 } # Table 2 of Yuan et al. (2013) https://doi.org/10.1093/mnras/stt039\n",
    "    return {\"g\": A_V*1.205, \"r\": A_V*0.848, \"i\":A_V*0.630 } # Table 3 of Wang and Chen (2019)\n",
    "\n",
    "\n",
    "\n",
    "def mag_absolute_to_apparent(m, distance, extinction):\n",
    "    \"\"\"\n",
    "    Function that corrects absolute magnitudes by distance modulus and extinction, to get apparent magnitudes\n",
    "    \n",
    "    m: absolute magnitude(s)\n",
    "    distance: in pc\n",
    "    extinction: in mag\n",
    "    \"\"\"\n",
    "    return m + 5.0*np.log10(distance) - 5 + extinction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the observed CMD with isochrones\n",
    "\n",
    "With all this in hand, we will now build an interactive matplotlib plot, displaying the observed CMD, and overplotting isochrones of selected age and metallicity. For this we define one more helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_apparent_isochrone(vrot_index, metallicity_index, age_index, distance=10, A_V=0):\n",
    "    \"\"\"\n",
    "    Helper function to get a specific isochrone at a specific distance and total extinction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computing the extinctions:\n",
    "    extinctions = extinction_law(A_V)\n",
    "    \n",
    "    # Obtaining the corrected magnitudes:\n",
    "    iso_app_g = mag_absolute_to_apparent(isochrones[vrot_index][metallicity_index][age_index][\"g\"], distance, extinctions[\"g\"])\n",
    "    iso_app_r = mag_absolute_to_apparent(isochrones[vrot_index][metallicity_index][age_index][\"r\"], distance, extinctions[\"r\"])\n",
    "    iso_app_i = mag_absolute_to_apparent(isochrones[vrot_index][metallicity_index][age_index][\"i\"], distance, extinctions[\"i\"])\n",
    "    \n",
    "    # A fancy string describing the isochrone, with some LaTeX formatting:\n",
    "    label_string = f\"Age {(10.0**logages[age_index])/(1e9):.2f} Gyr, \" \\\n",
    "        + f\"[Fe/H] = {metallicities[metallicity_index]:.2f}, \" \\\n",
    "        + r\"$v/v_{\\mathrm{crit}}$ = \" + f\"{vrots[vrot_index]}, \" \\\n",
    "        + f\"$d$ = {distance:.0f} pc, \" \\\n",
    "        + r\"$A_{\\mathrm{V}}$ = \" + f\"{A_V:.2f}\"\n",
    "\n",
    "    return (iso_app_g, iso_app_r, iso_app_i, label_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the interactive plot, using matplotlib sliders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial position of sliders:\n",
    "init_distance = 10.0\n",
    "init_age_index = 50\n",
    "init_metallicity_index = 12\n",
    "init_A_V = 0.0\n",
    "init_vrot_index = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.subplots_adjust(left=0.30, bottom=0.1) # making room for the sliders\n",
    "\n",
    "# Plotting the observed data \n",
    "cbar = ax.scatter(\n",
    "    cat[\"median_mag_sum_4_r\"] - cat[\"median_mag_sum_4_i\"],\n",
    "    cat[\"median_mag_sum_4_r\"],\n",
    "    s = 5,\n",
    "    c = cat[\"separation\"].value # color represents separation between star and cluster center\n",
    ")\n",
    "\n",
    "# Plotting the isochrone\n",
    "(g, r, i, label_string) = get_apparent_isochrone(init_vrot_index, init_metallicity_index, init_age_index, init_distance, init_A_V)\n",
    "line, = ax.plot(r-i, r, color=\"red\", linewidth=1.0) \n",
    "text = ax.text(0.5, 0.95, label_string, color=\"red\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "# The function to be called anytime a slider or botton is changed\n",
    "def update(val):\n",
    "    vrot_index = vrot_button.index_selected\n",
    "    metallicity_index = metallicity_slider.val\n",
    "    age_index = age_slider.val\n",
    "    distance = dist_slider.val\n",
    "    A_V = ext_slider.val\n",
    "    (g, r, i, label_string) = get_apparent_isochrone(vrot_index, metallicity_index, age_index, distance, A_V)\n",
    "    line.set_xdata(r-i)\n",
    "    line.set_ydata(r)\n",
    "    text.set_text(label_string)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Slider to control the distance\n",
    "axdist = fig.add_axes([0.05, 0.25, 0.0225, 0.6])\n",
    "dist_slider = matplotlib.widgets.Slider(\n",
    "    ax=axdist,\n",
    "    label=r\"$d$ [pc]\",\n",
    "    valmin=10,\n",
    "    valmax=10000,\n",
    "    valinit=init_distance,\n",
    "    orientation=\"vertical\"\n",
    ")\n",
    "\n",
    "# Slider to control the age\n",
    "axage = fig.add_axes([0.09, 0.25, 0.0225, 0.6])\n",
    "age_slider = matplotlib.widgets.Slider(\n",
    "    ax=axage,\n",
    "    label=r\"$i_{\\mathrm{Age}}$\",\n",
    "    valmin=0,\n",
    "    valmax=len(logages)-1,\n",
    "    valstep=1,\n",
    "    valinit=init_age_index,\n",
    "    orientation=\"vertical\"\n",
    ")\n",
    "\n",
    "# Slider to control the metallicity\n",
    "axmetal = fig.add_axes([0.13, 0.25, 0.0225, 0.6])\n",
    "metallicity_slider = matplotlib.widgets.Slider(\n",
    "    ax=axmetal,\n",
    "    label=r\"$i_{\\mathrm{[Fe/H]}}$\",\n",
    "    valmin=0,\n",
    "    valmax=len(metallicities)-1,\n",
    "    valstep=1,\n",
    "    valinit=init_metallicity_index,\n",
    "    orientation=\"vertical\"\n",
    ")\n",
    "\n",
    "# Slider to control the extinction\n",
    "axext = fig.add_axes([0.17, 0.25, 0.0225, 0.6])\n",
    "ext_slider = matplotlib.widgets.Slider(\n",
    "    ax=axext,\n",
    "    label=r\"$A_{\\mathrm{V}}$\",\n",
    "    valmin=0.0,\n",
    "    valmax=3.0,\n",
    "    valinit=init_A_V,\n",
    "    orientation=\"vertical\"\n",
    ")\n",
    "\n",
    "# Radio buttons to control the rotation\n",
    "axvrot = fig.add_axes([0.05, 0.1, 0.14, 0.08])\n",
    "vrot_button = matplotlib.widgets.RadioButtons(\n",
    "    ax=axvrot, \n",
    "    labels=(\"No rotation\", r\"$v/v_{\\mathrm{crit}} = 0.4$\"),\n",
    "    active=init_vrot_index\n",
    ")\n",
    "\n",
    "# Register the update function with each slider and button:\n",
    "age_slider.on_changed(update)\n",
    "dist_slider.on_changed(update)\n",
    "metallicity_slider.on_changed(update)\n",
    "ext_slider.on_changed(update)\n",
    "vrot_button.on_clicked(update)\n",
    "\n",
    "# Finalize plot\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(cbar, label=f\"Separation to target center in {cat['separation'].unit}\")\n",
    "ax.set_xlabel(\"$r$ - $i$\")\n",
    "ax.set_ylabel(\"$r$\")\n",
    "ax.set_title(object_to_process)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the CMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Question\n",
    "What features do you see in the observed CMD? Describe your data.\n",
    "```\n",
    "\n",
    "```{admonition} Question\n",
    "What photometric aperture radius gives the cleanest CMD? Apart from looking at the CMD itself, feel invited to make and discuss dedicated plots to compare magnitudes in different apertures. If the observing conditions were problematic, it might be interesting to visualize the measurements from individual exposures, instead of just considering their median. \n",
    "```\n",
    "\n",
    "```{admonition} Question\n",
    "Optionally, you could compute uncertainty estimates for your magnitude measurements and visualize those on the CMD. If you chose do so, describe how you computed them, and what sources of uncertainty you considered.\n",
    "```\n",
    "\n",
    "```{admonition} Question\n",
    "By comparing the calibrated CMD to the synthetic isochrones, give an estimate of the age and distance of your cluster, and potentially also of the metallicity and extinction. Potentially, you can discuss how some features of your CMD help in constraining these parameters.\n",
    "```\n",
    "\n",
    "```{admonition} Question\n",
    "Discuss the difficulty to get estimates (and uncertainty estimates) for these quantities. You could create CMDs with several isochrones to illustrate your points.\n",
    "If you would have to quantify uncertainties, how could you approach this?\n",
    "```\n",
    "\n",
    "```{admonition} Question\n",
    "Provide a comparison with values from the literature (at least for distance and age).\n",
    "```\n",
    "\n",
    "```{admonition} Question\n",
    "Try to list the ingredients of this whole analysis that could possibly have issues. In other words, what do you think are the key assumptions of your analysis?\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12datared",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
